\chapter{Implementation}
   \phantomsection
\label{Implementation}	
In this chapter we describe the use cases we have chosen to implement and benchmark. We first describe and motivate our choice of use cases and, afterwards, give reasonable details on their implementation. We do implement four use cases that are ordered from the least complex to the most complex.
\section{Use Case Description}
 \phantomsection
\label{Use Case}	 
We have decided to implement every use case with Conclave and SMCQL for two parties. As ABY3 does not allow a two party protocol but requires at least three parties, we have implemented everything for ABY3 with three parties. For ABY3 there will always be only two parties that provide input data. The third party will not provide input data but will assist in the execution of the protocol. We consider this approche justified, as it is the exact approach Conclave and ABY3 use in their evaluation. And if the authors of the frameworks considers such an approach fair, then we do hold no objections against it.  
We will refer to first party that provides input as Alice and to the second party that provides input as Bob. Furthermore if a framework is not capable of replicating the semantic of a use case to entirely, we do use that functionality available to implement the most similar semantic the framework can provide. For example use case two features boolean logic, but Conclave does not feature an explicit boolean logic. Therefore we use integers where the integer one represents the value true and the integer zero repents false.   
\paragraph{Use Case One}
For our first use case, we have chosen a single join. A single join may not be a very complex use case but it is not irrelevant as joins are of great importance for practically every relational database query. It is estimated that over 60 \% of privacy-sensitive analytics queries include at least one join \cite{johnson2017practical}. In our first experiment, Alice and Bob each hold one table. Each of these tables consists of 4 columns. The first column serves as the primary key that is used for the join. The other 3 columns are filled with random non-negative integers and simulate user data. We have chosen to use non-negative integers, because the usage of negative integers has resulted in an  increased frequency of various bugs and other undesirable behaviour. We are calculating an \hyperref[Databases]{[equi join]}  with the primary key generated in such a way that 50 \% of the entries in each table will match the join criteria. We do not generate the primary key randomly, because they size of output relation depends on it and we want those sizes to be consistent between individual executions. As result, we will reveal the entire outcome of the join. So the primary utility provided by the use of MPC operations is the fact that the entries that do not match the join criteria are obscured.

  \phantomsection
\label{SQL1_label}				
\begin{lstlisting}[caption={ Functional equivalent SQL statement for our first use case  }]
SELECT * 
FROM Alice A JOIN Bob B 
ON  A.primary_key = B.primary_key
\end{lstlisting}
   \phantomsection
\label{SQL1}
	  \phantomsection
	\label{Use Case two}		
\paragraph{Use Case Two}
Computing joins alone is of limited use if the result of the join can not be subject to further selection. Therefore in our second use case we will first compute a join and the query the result with a classic ``SELECT ... FROM ... WHERE'' statement. Similar to first experiment Alice and Bob again each hold one table. The tables consist of two columns. The first column serves as primary key and the second column contains a boolean values that is generated at random. For our experiment we will in a first step compute the natural join of the two tables, where the primary key column zips the two tables together. The primary keys will be again generated in such a way that 50 \% of the columns will be included in the join. In a second step we will apply a where filter to the result of the join and eliminate every row that does not have two identical boolean values. This use case functions also as a simple showcase example for composability and will show how well this mechanism functions in practise.    
  \phantomsection
\label{SQL2_label}		
\begin{lstlisting}[caption={Functional equivalent SQL statement for our second use case}]
	SELECT PrimaryKey, AliceBool, BobBool
	From AliceTable 
	NATURAL JOIN BOB TABLE
	WHERE AliceBool = BobBool
\end{lstlisting}

%\paragraph{Use Case Three}
%Besides joins, another very important group of SQL operations are aggregate functions. Over a third of all privacy-sensitive analytics queries requires a aggregation \cite{johnson2017practical}. Therefore our third use case is centred around an aggregate function, or more precisely a maximum operator.  TODO
%In our third experiment Alice and Bob each hold one table. The tables consist of two columns each. Like in our first and second use case the first column will function as primary key and will be used for a join. The second column will be the column we aggregate over. In a first step we will be compute the join of the two columns  
 

\paragraph{Use Case Three}
For our third and last use case, we test a special feature of Conclave. Conclave features a mechanic, that allows revealing some of the columns of the input data. The revelation of the input data allows them to apply optimizations that speed up the computation while preserving the privacy of the other columns. For a more detailed description see and \hyperref[Trust_label]{Conclave's trust annotations in Chapter 3}. Therefore in our third use case, we are going to replicate the setup of our first use case but this time we will allow the leakage of the primary key column. Such leakage will allow Conclave to apply its optimization. Replicating the setup of the first use case enables us, to compare the results of the third use case to the first use case. This comparison will show how big the speed up of these optimizations is in practice. 

















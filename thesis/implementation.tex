\chapter{Benchmarking}
For benchmarking performance there is often a variety of different metrics that are relevant and require to be measured with great care, as flawed or unclean measuring may deteriorate the value of the results. In this chapter, we describe the different metrics we want to benchmark and the different tools we use to achieve clean results. 

\section{Measuring Runtime}
A basic metric of how well a program functions, is its runtime. Time is often measured in either wall-clock time or process time. Wall-clock time references, as the name implies, the passing of time on a wall-clock while the program runs. 
Process time resembles the actual time a CPU was used by the program. If, for example, the process blocks for a longer period of time, its wall-clock and process execution time may differ by a large amount. Typical reasons for a for a process to block would be that it waits for a slow hard drive or for incoming network traffic from another party. One needs to be careful what time is measured and that it is measured precisely. Otherwise one may obtain flawed or unfairly biased results. We measure both wall-clock and process execution time, as this allows us a far a more detailed analysis. In particular, this approach enables us the evaluate the difference between process time and wall-clock time, which indicates how long a process was blocked. In order to do so, tool-aided measuring is required.

\paragraph{Measuring Space}
Besides time another metric we measure is space

\paragraph{Conclave}
Conclave is based on Python. Python comes with a ''batteries included'' approach, as it features a comprehensive standard library. Therefore plenty of tools, that provide valuable utility for us, are already integrated within python. Two such tools are timeit \cite{time} and the python profiler \cite{cProfile}, both are python libraries that offer a simple way to measure wall-clock or process execution time. Timeit measures exclusively end-to-end execution time, or in other words, the time the execution takes from one end to another. The python profiler comes with a more detailed analysis that includes detailed information on which functions have been executed, how often they have been executed, and how long it took to execute them. The extra utility provided by the python profiler does not come for free, compared to timeit, it has significant overhead that slows the execution down \cite{cProfile}. Therefore using it would result in an unfair disadvantage for Conclave. Thus we have initially decided to use timeit to measure the execution time of Conclave. One significant disadvantage of timeit, is its inability to measure wall-clock and process time simultaneously. For this reason, in order to measure both of these values, it is required to perform each measurement twice, which doubles the time required and is impractical. Therefore we have moved away from this approach and use time, the tool with which we measured SMCQL's execution time.  
\paragraph{SMCQL}

TODO time \cite{time_sh}
\paragraph{ABY3}
Since ABY3 is based on C++, we can not use the python specific tools we use for Conclave. Fortunately the cryptoTools library \cite{cryotoTools} is integrated into ABY3. CryptoTools is a C++ toolbelt that features a variety of tools for building cryptographic protocols. Among these utilities is a benchmarking tool for measuring runtime. With cryptoTools it is possible to measure end-to-end execution time or to measure the execution time of specific parts of the protocol. As croytoTools provides the functionality we need and is already "inbuilt" into ABY3, we have decided to use it for measuring ABY3's runtime. For a detailed example of how we utilise this tool in our benchmarking, see our description of our implementation of our second use-case in \hyperref[Implemetation]{Section 6}.




\section{Networking}
In our standard setup all parties run on the same machine and communicate through localhost. This simulates a practically perfect LAN connection with very low latency and high throughput. It is also of interest how well the frameworks function in less ideal conditions. Therefore we are also simulate a suboptimal wide area network(WAN) connection with high latency and limited bandwidth.

In order to do so we require a proxy server. Instead of connecting the parties to one another we connect them to the proxy server and the proxy server forwards the incoming messages to the addressed parties. To simulate a slow connection with high latency the proxy server delays incoming messages. Setting up such a proxy server is non trivial task, one challenge in particular is mapping the various connections to one another, in a correct way. This task is made more difficult by the fact that the different frameworks handle their connections in various different ways. In ABY3 for example, each party holds one direct connection to every other party. One the other hand in Conclave, every party is connected to a Node.js server that forwards the messages. In order handle these various approaches correctly, an analysis of the communication patterns is required. An additional factor that complicates our task is the fact that different frameworks use various different protocols to communicate. For example Conclave uses among others HTTP(hypertext transfer protocol),while ABY3 utilities plain TCP. Checking implementation details and source code is a target-oriented approach for such an analysis , another tool that helped us to understand the communication patterns is Wireshark.      
\paragraph{Wireshark}
Wireshark \cite{wireshark} is an open source packet sniffer that allows to capture network traffic and saves it for a detailed analysis. Wireshark supports the analysis of numerous different protocols, among these are plain TCP, HTTP and websockets. Hence Wireshark supports all the protocols that our frameworks relies on, and therefore are of relevance for our work. With Wireshark we have been able to record the communication of our parties and pin down the exact communication patterns. Another utility Wireshark provides for us, is the ability to record communication once our proxy was setup up. With these recordings we have been able to verify that our proxy does indeed function as intended.                  

 \paragraph{Toxiproxy}
 Both ABY3 and SMCQL implement communication between parties based on a plain standard socket. In the case of ABY3 it is the standard C++ socket. For SMCQL it is the standard java socket. Both of these are TCP based and can be proxied with a standard TCP proxy. For this purpose we use Shopify's Toxiproxy \cite{toxiproxy}. Toxiproxy is a Go framework that allows to simulate different hazardous network conditions. These include a connection that delays its messages to simulate a high latency setup. Once the proxy server is setup it can be configured over the command line interface (CLI) or alternatively over an HTTP(hypertext transfer protocol) interface, Toxiproxy provides multiple different dedicated HTTP clients for this purpose. The clients differ in that they offer an interface in different programming languages. We have chosen to use the provided Ruby client as it is the one that provides the most extensive documentation. 
 A simplified example how to use Toxiproxy to simulate latency can be found in \hyperref[the_label]{Listing 5.1}. In order to use Toxiproxy, we first set up the proxy so it starts to accept new connections. This is done by calling Toxiproxy populate and specifying to which address the proxy listens to and the address the messages get forwarded to.
 By default Toxiproxy does not add any network limitations to a connection. In our example we apply two limitations, to simulate a latency of 1000ms. The first limitation is applied to the "upstream" direction. Therefore it affects every message that is send towards the server from the address the server listens to. The second limitation is applied to the "downstream" direction. Therefore it affects every response that comes from the address the server listens to.    
 
   \phantomsection
 \label{Toxi_label}				
 \begin{lstlisting}[caption={Setting up a proxy that simulates latency between two parties with Toxiporxy}]
 #First we instantiate a connection between the two parties. 
 Toxiproxy.populate([
 {
 	name: "aby3_party2_party1",
 	#party 3 sends its messages for party1 to port 50010 therefore the proxy must listen to this port
 	listen: "127.0.0.1:50010",   
 	#party 1 listens to port 50001 therefore theproxy must forward to this port
 	upstream: "127.0.0.1:50001"  
}
 ])
 #Then we simulate a latency of 1000ms 
 toxiproxy-cli add aby3_party2_party1 -type latency -name upstream latency=1000 -upstream
 toxiproxy-cli add aby3_party2_party1 -type latency -name downstream latency=1000 -downstream
 
 \end{lstlisting}
 \paragraph{Node-Http-Proxy}
 Conclave's communication is based partially on websockets and partially on plain standard HTTP.
 Websockets are implemented on top of TCP. In particular, websockets use a single TCP socket for bidirectional communication. Therefore proxying Conclave cannot be done with a simple TCP proxy. Instead we use node-http-proxy a library for proxying HTTP that also supports websockets. With node-http-proxy we are able to delay massages to simulate high latency. It is also possible to measure the amount of data sent and received over a connection.
 Node-http-proxy is based on JavaScript and relies heavily on an event driven programming paradigm. A simplified example how to use node-http-proxy can be found in \hyperref[the_label]{Listing 5.2}. In our example we first create a proxy server and specify the address it forwards to. In a second step we create a a HTTP server that delays every incoming message for 500 milliseconds and then sends it to the proxy server. Subsequently we demonstrate how Node-Http-Proxy make use of the event driven programming paradigm. In the third step we subscribe to the "proxyReqWs" event. The "proxyReqWs" event is raised by the proxy each time an outgoing websocket message is received. The event is raised before the message is transmitted to its destination and we can submit an anonymous function as event handler. The event handler is executed for each message before the message is transmitted. We could, for example, use this mechanism to modify responses or for various other practical use cases. In our specific example, we provide a function that waits 500 milliseconds to simulate latency. In the fourth step we subscribe to the "close" event. The "close" event is raised each time a websocket is closed. We use our event handler to save the amount of bytes transmitted though the websocket. This is a showcase example, of how a proxy can help to measure important metrics that would be non trivial to  measure otherwise.
  \phantomsection
  \label{the_label}				
 \begin{lstlisting}[caption={Setting up a proxy that simulates latency with node-http-proxy}]
	#create proxy server and specify the adress it forwards to
	#with the ws:true parameter we enable support for websockets
 	var proxy = new httpProxy.createProxyServer({
 		target: {
 			host: 'localhost',
 			port: 9005
 		},
 		ws:true 
 	});
 	 # Here we crate a standart HTTP server that delays every incoming message for 500ms and then forwars it the proxy server.
 	var proxyServer = http.createServer(function (req, res) {
 		setTimeout(function () {
 			proxy.web(req, res);
 		}, 500);
 	}).listen(9000);
 	# for every outgoing message the proxy emits a proxyReqWs event that we react to and delays the message for 500 milliseconds
 	proxy.on('proxyReqWs', function(){
 		 setTimeout(function(){ },500) 
 	 });
  	# each time a connection is closed the proxy emits a "close" event that we react to and save the amount of bytes transmitted through the connection
 	proxy.on('close' ,function (res,socket,head) { 
 		send  = socket.bytesRead;
 		received  = socket.bytesWritten;
 	});
 \end{lstlisting}



 
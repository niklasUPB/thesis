	
\chapter{Benchmarking}
\phantomsection
\label{Benchmarking}
For benchmarking efficiency there is often a variety of different metrics that are relevant and require to be measured with great care, as flawed or unclean measuring may deteriorate the value of the results. In this chapter, we describe the different metrics we want to benchmark and the different tools we use to achieve valid results. 

\section{Measuring Runtime}
A basic metric of how well a program works, is its runtime. Time is often measured in either wall-clock time or process time. Wall-clock time references, as the name implies, the passing of time on a wall-clock while the program runs. 
Process time resembles the actual time a CPU was used by the program. If, for example, the process blocks for a longer period of time, its wall-clock and process execution time may differ by a large amount. Typical reasons for a for a process to block would be that it waits for a slow hard drive or for incoming network traffic from another party. One needs to be careful what time is measured and that it is measured precisely. Otherwise one may obtain flawed or unfairly biased results. We measure both wall-clock and process execution time, as this allows us a far a more detailed analysis. In particular, this approach enables us to evaluate the difference between process time and wall-clock time, which indicates how long a process was blocked. In order to do so, tool-aided measuring is required. Measuring the individual frameworks is always trivial. Since the frameworks were implemented in different languages, different tools are available for measuring the individual frameworks. 
  \phantomsection
\label{time}	
\paragraph{SMCQL}%TODO blackbox metapher.
\code{time} \cite{time_sh} is a command line interface(CLI) command that is designed to benchmark the execution of other CLI commands. It is feasible to wrap the execution of a secure multiparty protocol in a .sh script and measure the performance of the script. Therefore \code{time} is in theory able to measure any of frameworks. One of \code{time's} advantages are the many different metrics it is able to measure, these include wall-clock and process time but also average memory requirements and maximum memory requirements. One major disadvantage of \code{time} is its inability to measure individual parts of a protocol in more detail. For SMCQL \code{time} perfectly fits our requirements. Therefore we use \code{time} to benchmark SMCQL  


\paragraph{Conclave}
Because \code{time} is able to measure shell commands we could also use it measure Conclave. Conclave is based on Python and Python comes with a ``batteries included'' approach, as it features a comprehensive standard library. Therefore plenty of tools, that provide valuable utility for us, are already integrated within python, because of this, there are other tools that are also valid candidates to measure Conclave. Two such candidates are timeit \cite{time} and the python profiler \cite{cProfile}, both are python libraries that offer a simple way to measure wall-clock or process execution time. Timeit measures exclusively end-to-end execution time, or in other words, the time the execution takes from one end to another. The python profiler comes with a more detailed analysis that includes detailed information on which functions have been executed, how often they have been executed, and how long it took to execute them. The extra utility provided by the python profiler does not come for free, compared to timeit, it has significant overhead that slows the execution down \cite{cProfile}. Therefore using it would result in an unfair disadvantage for Conclave. One significant disadvantage of timeit, is its inability to measure wall-clock and process time simultaneously. For this reason, in order to measure both of these values, it is required to perform each measurement twice, which doubles the time required and is impractical. Therefore we use the \code{time} tool with which we also measured SMCQL's execution time.  



\paragraph{ABY3}
 To benchmark ABY3 we use the cryptoTools library \cite{cryotoTools}, which is integrated into ABY3. The cryptoTools library is a C++ toolbelt that features a variety of tools for building cryptographic protocols. Among these utilities is a benchmarking tool for measuring runtime. With cryptoTools it is possible to measure the execution time of specific parts of the protocol. The croytoTools library provides the features we need and is already ``inbuilt'' into ABY3, therefore we have decided to use it for measuring ABY3's runtime. For a detailed example of how we utilise this tool benchmarking, see the description of our implementation for the second use case in \hyperref[Implementation]{Section 5}.




\section{Networking}
In our standard setup all parties run on the same machine and communicate through localhost. This simulates a practically perfect local area network (LAN) connection with very low latency and high throughput. It is also of interest how well the frameworks works in less ideal conditions. In particular, we also simulate a suboptimal wide area network(WAN) connection with high latency and limited bandwidth.

In order to do so we require a proxy server. Instead of connecting the parties to one another we connect them to the proxy server and the proxy server forwards the incoming messages to the addressed parties. To simulate a slow connection with high latency the proxy server delays incoming messages. Setting up such a proxy server is non trivial task, one challenge in particular is mapping the various connections to one another, in a correct way. This task is made more difficult by the fact that the different frameworks handle their connections in various different ways. In ABY3 for example, each party holds one direct connection to every other party. Differently, in Conclave, every party is connected to a Node.js server that forwards the messages. In order to handle these various approaches correctly, an analysis of the communication patterns is required. An additional factor that complicates our task is the fact that different frameworks use various different protocols to communicate. For example Conclave uses among others HTTP,while ABY3 utilities plain TCP. Checking implementation details and source code is a target-oriented approach for such an analysis , another tool that helped us to understand the communication patterns is Wireshark.      
\paragraph{Wireshark}
Wireshark \cite{wireshark} is an open source packet sniffer that allows to capture network traffic and saves it for a detailed analysis. Wireshark supports the analysis of numerous different protocols, among these are plain TCP, HTTP and websockets. Hence Wireshark supports all the protocols that our frameworks relies on, and therefore are of relevance for our work. With Wireshark we have been able to record the communication of our parties and pin down the exact communication patterns. Another utility Wireshark provides for us, is the ability to record communication once our proxy was setup. We also used Wireshark's recordings to confirm that our proxy works correctly once it was setup and used it detect error in our configuration. 
                

 \paragraph{Toxiproxy}
 Both ABY3 and SMCQL implement communication between parties based on a plain standard socket. In the case of ABY3 it is the standard C++ socket. For SMCQL it is the standard java socket. Both of these are TCP based and can be proxied with a standard TCP proxy. For this purpose we use Shopify's Toxiproxy \cite{toxiproxy}. Toxiproxy is a Go framework that allows to simulate different hazardous network conditions. These include a connection that delays its messages to simulate a high latency setup. Once the proxy server is setup it can be configured over the command line interface (CLI) or alternatively over an HTTP interface, Toxiproxy provides multiple different dedicated HTTP clients for this purpose. The clients differ in that they offer an interface in different programming languages. We have chosen to use the provided Ruby client as it is the one that provides the most extensive documentation. 
 A simplified example on how to use Toxiproxy to simulate latency can be found in \hyperref[the_label]{Listing 5.1}. In order to use Toxiproxy, we first set up the proxy so it starts to accept new connections. This is done by calling Toxiproxy populate and specifying to which address the proxy listens to and the address the messages get forwarded to.
 By default Toxiproxy does not add any network limitations to a connection. In our example we apply two limitations, which simulate a latency of 1000ms. The first limitation is applied to the ``upstream'' direction. Therefore it affects every message that is send towards the server from the address the server listens to. The second limitation is applied to the ``downstream'' direction. Therefore it affects every response that comes from the address the server listens to.    
 
   \phantomsection
 \label{Toxi_label}				
 \begin{lstlisting}[caption={Setting up a proxy that simulates latency between two parties with Toxiporxy}]
 #First we instantiate a connection between the two parties. 
 Toxiproxy.populate([
 {
 	name: "aby3_party2_party1",
 	#party 3 sends its messages for party1 to port 50010 therefore the proxy must listen to this port
 	listen: "127.0.0.1:50010",   
 	#party 1 listens to port 50001 therefore theproxy must forward to this port
 	upstream: "127.0.0.1:50001"  
}
 ])
 #Then we simulate a latency of 1000ms 
 toxiproxy-cli add aby3_party2_party1 -type latency -name upstream latency=1000 -upstream
 toxiproxy-cli add aby3_party2_party1 -type latency -name downstream latency=1000 -downstream
 
 \end{lstlisting}
 \paragraph{Node-Http-Proxy}
 Conclave's communication is based partially on websockets and partially on plain standard HTTP.
 Websockets are implemented on top of TCP. In particular, websockets use a single TCP socket for bidirectional communication. Therefore proxying Conclave cannot be done with a simple TCP proxy. Instead we use node-http-proxy a library for proxying HTTP that also supports websockets. With node-http-proxy we are able to delay messages to simulate high latency. It is also possible to measure the amount of data sent and received over a connection.
 Node-http-proxy is based on JavaScript and relies heavily on an event driven programming paradigm. A simplified example how to use node-http-proxy can be found in \hyperref[the_label]{Listing 5.2}. In this example we first create a proxy server and specify the address it forwards to. In a second step we create a a HTTP server that delays every incoming message for 500 milliseconds and then sends it to the proxy server. Subsequently we demonstrate how Node-Http-Proxy make use of the event driven programming paradigm. In the third step we subscribe to the ``proxyReqWs'' event. The ``proxyReqWs'' event is raised by the proxy each time an outgoing websocket message is received. More concrete event is raised before the message is transmitted to its destination and we can submit an anonymous function as event handler. The event handler is executed for each message before the message is transmitted. This for example enables to modify responses or to apply various other practical use cases. In our specific example, we provide a function that waits 500 milliseconds to simulate latency. In the fourth step we subscribe to the ``close'' event. The ``close'' event is raised each time a websocket is closed. We use our event handler to save the amount of bytes transmitted though the websocket. This is a showcase example, of how a proxy helps to measure important metrics that would be non trivial to measure otherwise.
  \phantomsection
  \label{the_label}				
 \begin{lstlisting}[caption={Setting up a proxy that simulates latency with node-http-proxy}]
	#create proxy server and specify the adress it forwards to
	#with the ws:true parameter we enable support for websockets
 	var proxy = new httpProxy.createProxyServer({
 		target: {
 			host: 'localhost',
 			port: 9005
 		},
 		ws:true 
 	});
 	 # Here we crate a standart HTTP server that delays every incoming message for 500ms and then forwars it the proxy server.
 	var proxyServer = http.createServer(function (req, res) {
 		setTimeout(function () {
 			proxy.web(req, res);
 		}, 500);
 	}).listen(9000);
 	# for every outgoing message the proxy emits a proxyReqWs event that we react to and delays the message for 500 milliseconds
 	proxy.on('proxyReqWs', function(){
 		 setTimeout(function(){ },500) 
 	 });
  	# each time a connection is closed the proxy emits a "close" event that we react to and save the amount of bytes transmitted through the connection
 	proxy.on('close' ,function (res,socket,head) { 
 		send  = socket.bytesRead;
 		received  = socket.bytesWritten;
 	});
 \end{lstlisting}

\section{Measuring Memory Consumption}
Another metric we collect is the consumption of memory. Sometimes it is possible to speed up computations at the cost of their memory consumption, so it is not sufficient to measure only runtime to get a fair measure of efficiency. A well-known example of such a time-memory trade-off are Rainbow Tables \cite{rainbow}. Another reason to measure memory usage is the fact that during our survey it often turned out to be a limiting factor for the size of datasets that are feasible to evaluate. 
For each framework we have measured its maximum memory consumption during an execution. With \hyperref[time]{time} we already have a tool that is able to measure the memory consumption of each framework in a sufficient way, therefore we use \code{time} to do so.


 
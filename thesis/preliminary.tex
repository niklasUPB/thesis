\chapter{Preliminary}
\section{Secure Multiparty Computation}
In the an secure multiparty computation(short MPC) scenario there are n parties $ p_0,\dots,p_{n-1} $. They want to compute an agreed upon functionality F($ x_0,\dots,x_{n-1} $). A functionality is a function that is allowed to have internal randomness, so its not function in the strict mathematically sense of the word. 
Each party $ p_i $ holds an input value $ x_i $. 
The parties hold their input private and do not want to reveal any information about it. The Goal of secure multiparty computation is to develop a protocol  $ \pi $ that enables them to jointly compute F($ x_0,\dots,x_{n-1}. $). The security goal of "not revelling the inputs" is often formalised through the Real-/Ideal-World Paradigm. 


\subsection{Real World and Ideal World}
When modelling security of secure multiparty computation we compare the real world, to a perfect ideal world, where the problem can be solved in a perfect way.
\paragraph{Real World}
In the real world there exists a protocol $\pi $ that enables the parties to compute F. All parties execute the protocol together. During the execution they exchange several rounds of communication. The attacker or adversary has the ability to corrupt one or more of the parties. His capability to influence the corrupted parties is an important parameter and may differ based on different security assumptions. These may range for example from a relative weak adversary that can only read massages to a very powerful adversary. We explain the adversary models that are of importance for our benchmarks in \hyperref[sec:Adversarial Models]{Section 3.2} in detail.
The real world view of party A consist of the input of A, all massages A sends or receives during the execution of the protocol and his internal randomness. The protocol achieves the security goal of confidentially if the attacker is unable to derive new information from the views of the parties he did corrupt. ...
\paragraph{Ideal World}\todo[fancyline]{Schaubild einf√ºgen ?}
In the Ideal World the parties to not need run a protocol. Instead they can rely on a trusted, incorruptible third party P that aids them. With the aid of P, the parties can evaluate F in two simple steps. In a first round of communication every party send P its input. P now holds all information it needs to compute F. Afterwards P can send each party the result in a second round of communication. Like in the real world, in the ideal world their also exists an adversary. Similar to his real world counterparty he is also able to corrupt one or more parties.    Compared to his real world counter part the ideal world adversary has otherwise very limited ability's. He can only see the input and output of the parties he corrupts. Since the computation with the aid of P produces no intermediate results that he can observe. Depending on the underlying security assumptions he also may be able to modify the input a corrupted party sends to P in the first round of communication. Because of these very limited ability's it is desired that for every adversary in the real world their exits a comparable powerful adversary in the ideal world. This is often formalised using simulation based proof.

\paragraph{Security}
Given an real-world adversary A , a secure multiparty protocol $\pi $ , and a functionality F for $\pi $ to be secure we require the existence of a so called simulator S.
S is an ideal world adversary for F that mirror's the behaviour of A. This means that S and A corrupt the same parties and also that if a A changes the output of F then S does the same. After S has performed its attack S outputs a real world view. $\pi $ is secure against A, if the view S outputs is indistinguishable from a view of A. This means that the real world attacker A cannot learn more then the ideal world attacker S. Despite the very limited ability's S has compared to A. Finally we say $\pi $  is secure against if, for all A $\pi $ is secure against A. 






















     

\section{Adversarial Models}
\label{sec:Adversarial Models}
There are multiple models and categorizations of adversary's and their capability's. These distinctions have significant impact on feasibility and difficulty of secure multiparty computation. In the following we will outline the models and assumptions that are of importance for our benchmarks. 

\paragraph{Passive Adversary vs Active Adversary}
A passive adversary can not force a corrupted party to deviate from the protocol in an any way. One could think of a passive adversary as a "read-only" adversary. As a passive adversary is only able to read the messages his corrupted parties receive or send. A active adversary can do everything a passive adversary can additionally he has the power to force a corrupted party to deviate from the protocol in an arbitrary way. So if for example the protocol would at some point require that each party choses an integer between 1 and n uniformly at random. 
Then a passive adversary would have no choice but to choose the integer between 1 and n uniformly at random. 
On the contrary an active adversary would be able to force a corrupted party to chose the value 42 or any other value that the adversary considers to be advantageous for him. In the ideal world a passive adversary is bound to forward the real input values. A active adversary can choose to ignore the real input and forward any value instead.

\paragraph{Monolithic Adversary}
In the following we will assume a monolithic adversary unless explicitly stated otherwise. This means that there is only a single adversary that controls all corrupt parties. For the honest parties a monolithic adversary is a worst-case scenario. A monolithic adversary is more powerful compared to multiple adversary's that control the same total amount of parties but to not corporate with each other. A protocol that is secure in the presence of a single adversary that corrupts n parties and is able to coordinate their efforts. Will be secure in the presence of up to n adversary's that corrupt n parties total and do not coordinate their efforts.   
\paragraph{General Adversary vs Threshold Adversary}
In the threshold MPC setting the adversary can choose to corrupt any party. The threshold adversary is only limited in the way that can at most corrupt t parties where t is set to be 0 < t < n. A common setting for t is t = $\left \lfloor{ \frac{n}{2} }\right \rfloor  $, which called the honest majority. For example and for n=3 the presence of an honest majority means, that it is assumed that the threshold adversary can corrupt at most 1 party. Threshold MPC best fits scenarios that feature a very homogenous group of parties. A general adversary is limited in his choice which party he corrupts by an adversary structure  
$ Z = \{ Z_1, \dots, Z_l  \} $. Where $ Z_i $ can be any set of parties. The general adversary must corrupt a set of parties  $ P $ such that there exists an $ x \in Z $ that holds $ P \subset x $. This allows for a flexible way to formalise assumptions. If for example in protocol there are two parties that hold a very vital role and one want to assume that no adversary can corrupt both of these parties. That can be formalised by using a general adversary an defining $ Z $ so that no element in  $Z $ contains both of these two parties.  
 
\paragraph{Static vs Dynamic Corruptions}
Another important distinction is the distinction between static and adaptive adversary's. A static adversary is bound to chose which parties he wants to corrupt before the execution of $ \pi $ starts. An adaptive adversary can corrupt a party during the execution of the protocol. This makes the adaptive adversary much more powerful. As he can try to identify "weak links" based on the information he gets during the execution of the protocol and then choose corrupt those.   


\subsection{Additional Properties}
\paragraph{binary secret sharing ???} 
\paragraph{garbled circuits ???}

\section{Databases}



coming soon
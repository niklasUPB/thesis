\chapter{Preliminary}
In this chapter we establish important vocabulary for our work. At first we provide an overview over the topic of Secure Multiparty Computation. That is followed by an brief explanation of some general techniques, on which the frameworks we benchmark are based on. 
Lastly we describe the semantics of different database operations, that are of importance for our benchmarks.  
\section{Secure Multiparty Computation}
In the an secure multiparty computation(short MPC) scenario there are n parties 
$ p_0,\dots,p_{n-1} $. They want to compute an agreed upon functionality F($ x_0,\dots,x_{n-1} $). A functionality is a function that is allowed to have internal randomness, so its not function in the strict mathematically sense of the word. 
Each party $ p_i $ holds an input value $ x_i $. 
The parties hold their input private and do not want to reveal any information about it. Hence, the Goal of secure multiparty computation is to develop a protocol  $ \pi $ that enables them to jointly compute F($ x_0,\dots,x_{n-1}. $). The security goal of "not revealing the inputs" is often formalised through the Real-/Ideal-World Paradigm. 


\subsection{Real World and Ideal World}
When modelling security of secure multiparty computation we compare the real world, to a perfect ideal world, where the problem can be solved in a perfect way.
\paragraph{Real World}
In the real world there exists a protocol $\pi $ which was designed to enable the parties to compute F. All parties execute the protocol together. During the execution they communicate for several rounds. The attacker or adversary has the ability to corrupt one or more of the parties. His capability to influence the corrupted parties is an important parameter and may differ based on different security assumptions. These may range for example from a relative weak adversary that can only read massages to a very powerful adversary. We explain the adversary models that are of importance for our benchmarks in \hyperref[sec:Adversarial Models]{Section 3.2} in detail.
The real world view of this attacker A consist of the inputs of each corrupted party, their obtained messages throughout the protocol and A's obtained messages. The protocol achieves the security goal of confidentially if the view A contains no more information beyond what can be deducted from the corrupted parties' input and outputs alone. 
\paragraph{Ideal World}\todo[fancyline]{Schaubild einf√ºgen ?}
In the ideal world the parties to not need run a protocol. Instead they can rely on a trusted, incorruptible third party P that aids them. With the aid of P, the parties can evaluate F in two simple steps. In a first round of communication every party send P its input. P now holds all information it needs to compute F. Afterwards P can send each party the result in a second round of communication. Like in the real world, in the ideal world their also exists an adversary. Similar to his real world counterparty he is also able to corrupt one or more parties. Compared to his real world counter part the ideal world adversary has otherwise very limited ability's. He can only see the input and output of the parties he corrupts. Especially the computation with the aid of P produces no intermediate results that he can observe. Depending on the underlying security assumptions he also may be able to modify the input a corrupted party sends to P in the first round of communication. For security we want to show that a real world attacker, effectively, learns nothing more than such an ideal world adversary with its clearly specified, limited capabilities. This is specified using the simulation paradigm.

\paragraph{Security}
Given a real-world adversary A, a secure multiparty protocol $\pi $, and a functionality F for $\pi $ to be secure we require the existence of a so called simulator S.
S is an ideal world adversary for F that has to indistinguishably simulate views the real world attacker A obtains in a protocol execution. To achieve this, S is only allowed to perform corruptions consistently with A's behaviour. This means that S and A corrupt the same parties and if A is an active adversary then S is allowed to change the inputs of its corrupted parties. After S has performed its attack, S outputs a real world view. $\pi $ is secure against A, if the view S outputs is indistinguishable from a view of A. This means that the real world attacker A cannot learn more than the ideal world attacker S. Despite the very limited ability's S has compared to A. Finally we say $\pi $  is secure against if, for all A $\pi $ is secure against A. 



\section{Adversarial Models}
\label{sec:Adversarial Models}
There are multiple models and categorizations of adversary's and their capability's. These distinctions have significant impact on feasibility and difficulty of secure multiparty computation. In the following we will outline the models and assumptions that are of importance for our benchmarks. 

\paragraph{Passive Adversary vs Active Adversary}
A passive adversary can not force a corrupted party to deviate from the protocol in any way. One could think of a passive adversary as a "read-only" adversary, as a passive adversary is only able to read the messages his corrupted parties receive or send. An active adversary is allowed do everything a passive adversary is allowed, more precisely the set of all ability's an active adversary has, is a super set of the set of all ability's an passive adversary has. Furthermore he has the additional power to force a corrupted party to deviate from the protocol in an arbitrary way. So if for example the protocol would at some point require that each party choses an integer between 1 and n uniformly at random ,then a passive adversary would have no choice but to choose the integer between 1 and n uniformly at random. 
On the contrary an active adversary would be able to force a corrupted party to chose the value 42 or any other value that the adversary considers to be advantageous for him. In the ideal world a passive adversary is bound to forward the real input values. A active adversary can choose to ignore the real input and forward any value instead.

\paragraph{Monolithic Adversary}
A common assumption is the assumption of a so called monolithic adversary. When assuming a monolithic adversary one assumes that , there is only a single adversary that controls all corrupt parties. For the honest parties a monolithic adversary is a worst-case scenario. Because monolithic adversary is more powerful then multiple adversary's that control the same total amount of parties but to not corporate with each other. A protocol that is secure in the presence of a single adversary that corrupts n parties and is able to coordinate their efforts, will be secure in the presence of up to n adversary's that corrupt n parties total and do not coordinate their efforts. In the following we will assume a monolithic adversary unless explicitly stated otherwise.
\paragraph{General Adversary vs Threshold Adversary}
One important distinction in modelling adversaries is the distinction between a general adversary and a threshold adversary.
In the threshold setting each party is a legitimate target for corruption and the threshold adversary is parametrized by a parameter t, 0<t<n, which denotes the limit of parties it is allowed to corrupt. A common setting for t is t = $\left \lfloor{ \frac{n}{2} }\right \rfloor  $, which called the honest majority. For example for n=3 the presence of an honest majority means, that it is assumed that the threshold adversary can corrupt at most 1 party. Threshold MPC best fits scenarios that feature a very homogenous group of parties. A general adversary is limited in his choice which party he corrupts by an adversary structure  
$ Z = \{ Z_1, \dots, Z_l  \} $. Where $ Z_i $ can be any set of parties. The general adversary must only corrupt a set of parties  $ P $ such that there exists an $ x \in Z $ that holds $ P \subset x $. This allows for a flexible way to formalise assumptions. If for example in a protocol there are two parties that hold a very vital role and one want to assume that no adversary can corrupt both of these parties, that can be formalised by using a general adversary an defining $ Z $ so that no element in  $Z $ contains both of these two parties.  
 
\paragraph{Static vs Dynamic Corruptions}
Another important distinction is the distinction between static and adaptive adversary's. A static adversary is bound to choose which parties he wants to corrupt before the execution of $ \pi $ starts. An adaptive adversary can corrupt a party during the execution of the protocol. This makes the adaptive adversary much more powerful. As he can try to identify "weak links" based on the information he gets during the execution of the protocol and then choose corrupt those.   


\subsection{General Techniques}
\paragraph{binary secret sharing} 
\paragraph{garbled circuits}

\section{Databases}
\label{Databases}
coming soon